function train_network(fldrArgs, imageSize, classNames, pixelLabelIDs, trainParams)
    fprintf("Network Training Started At: %s\n", datetime('now','TimeZone','local','Format','d-MMM-y HH:mm:ss Z'));
    modelFile = fullfile(fldrArgs.OutputFolder, fldrArgs.ModelFile);
    if exist(modelFile, 'file') ~= 2
        % create the training image datastore for the spectrograms
        imdsTrain = imageDatastore(fldrArgs.TrainImages, IncludeSubfolders=true, LabelSource="foldernames");

        % create the pixel data store
        pxds = pixelLabelDatastore(fldrArgs.LabelImages, classNames, pixelLabelIDs, IncludeSubfolders = true);

        % add train-test split for validation
        [imdsTrainSplit, imdsValSplit, pxdsTrainSplit, pxdsValSplit] = partition_semantic_segmentation_data(imdsTrain, pxds, 0.8);

        combinedTrain = combine(imdsTrainSplit, pxdsTrainSplit);
        combinedVal = []; % combine(imdsValSplit, pxdsValSplit);

        % Pass it the combined train datastore
        % Second param is 2 because we have 2 things coming from the datastore (image and pixel label)
        % MiniBatchSize is the size of the batch we want to use
        % MiniBatchFormat specifies the channel format of the outputs
        % Proceprocessing Environment set to parallel to run preprocessing on multiple CPU cores before feeding to GPU
        mbq = minibatchqueue(combinedTrain, 2, MiniBatchSize=trainParams.Minibatch, MiniBatchFormat=[ "SSCB" "" ], PreprocessingEnvironment="parallel");

        h = imageSize(1);
        w = imageSize(2);

        % define the image size and classes for the network
        netImgSize = [ h w 3 ]; % [ Height x Width x Channels ]
        numClasses = size(classNames, 2);

        % initialize unet
        % depth = 4;
        % encoderNetwork = pretrainedEncoderNetwork("googlenet", depth);
        unetNetwork = unet(netImgSize, numClasses, ...
                           NumFirstEncoderFilters=trainParams.NumFilters, ...
                           FilterSize=trainParams.FilterSize, ConvolutionPadding="same", ...
                           EncoderDepth=trainParams.EncdrDpth);

        if numClasses == 2
            lossFcn = "binary-crossentropy";
        else
            lossFcn = "crossentropy";
        end
        if trainParams.Optimizer == "adam"
            options = trainingOptions("adam", ...
                                  InitialLearnRate=trainParams.LearnRate, ...
                                  MiniBatchSize=trainParams.Minibatch, ...
                                  LearnRateSchedule=trainParams.LearnSche, ...
                                  CheckpointFrequency=1, ...
                                  InputDataFormats='SSCB', ...
                                  TargetDataFormats='SSCB', ...
                                  VerboseFrequency=1, ...
                                  ExecutionEnvironment="gpu", ...
                                  PreprocessingEnvironment="parallel", ... % "serial", "background", "parallel"
                                  Acceleration="auto", ...
                                  Plots="training-progress", ...
                                  Metrics=[ "accuracy", "fscore", "rmse" ], ...
                                  ValidationData=combinedVal, ...
                                  ValidationFrequency=30, ...
                                  ValidationDataFormats='SSCB', ...
%{
                                  ValidationPatience=5, ...
%}
                                  Shuffle='every-epoch');
            % Adam optimizer options
            options.GradientDecayFactor = trainParams.GradientDecay;
            options.SquaredGradientDecayFactor = trainParams.SquaredGradient;
            options.Epsilon = trainParams.Epsilon;
            options.L2Regularization = trainParams.L2;
            options.GradientThreshold = trainParams.GradientThreshold;
            options.GradientThresholdMethod = trainParams.GradientThresholdMethod;
            options.CategoricalInputEncoding = "integer"; % "integer", "one-hot"
%            options.CategoricalTargetEncoding = "integer"; % "auto", "integer", "one-hot"
            options.ResetInputNormalization = 1; % boolean, 1 is default
            options.BatchNormalizationStatistics = "auto"; % "auto", "population", "moving"
        end
        else
        % loss function definition (classification: "crossentropy", "index-crossentropy", "binary-crossentropy"), (regression: "mae", "mse", "huber")
            options = trainingOptions(trainParams.Optimizer, ...
        			              InitialLearnRate=trainParams.LearnRate, ...
                                  MaxEpochs=trainParams.MaxEpochs, ...
                                  MiniBatchSize=trainParams.Minibatch, ...
                                  LearnRateSchedule=trainParams.LearnSche, ...
                                  LearnRateDropFactor=trainParams.LearnDrop, ...
                                  LearnRateDropPeriod=trainParams.LDropPerd, ...
%{
                                  Momentum=trainParams.Momentum, ...
%}
                                  CheckpointFrequency=1, ...
                                  InputDataFormats='SSCB', ...
                                  TargetDataFormats='SSCB', ...
                                  VerboseFrequency=1, ...
                                  ExecutionEnvironment='gpu', ...
                                  Plots="training-progress", ...
                                  Metrics=[ "accuracy", "fscore", "rmse" ], ...
                                  ValidationData=combinedVal, ...
                                  ValidationFrequency=30, ...
                                  ValidationDataFormats='SSCB', ...
%{
                                  ValidationPatience=5, ...
%}
                                  Shuffle='every-epoch' ...
        );
        end

        save(fullfile(fldrArgs.OutputFolder, replace(fldrArgs.ModelFile, "trainnet", "debug")));
        [netTrained, ~] = trainnet(mbq, unetNetwork, lossFcn, options); % train
        currentfig = findall(groot, 'Tag', 'DEEPMONITOR_UIFIGURE'); % grab figure
        exportgraphics(currentfig, fullfile(fldrArgs.OutputFolder, "trainloss.png"));
        save(modelFile, 'netTrained');
    end

    fprintf("Network Training Finished At: %s\n", datetime('now','TimeZone','local','Format','d-MMM-y HH:mm:ss Z'));
end
